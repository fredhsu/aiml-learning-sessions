# 2026 AI/ML Learning Plan

I can read modern ML papers end-to-end and implement key ideas from scratch or minimal frameworks.

What “depth” means here

- Fewer topics, slower pace, more derivations and implementations
- Re-deriving things you already “sort of know”

Core areas to anchor the year

- Optimization & implicit regularization
- Representation learning & transformers (from first principles)
- One serious “from scratch” system (e.g., micrograd → transformer → small training loop)

Weekly process

- 3–4 focused sessions (60–90 min)
- One session is always write-or-implement, not read

Quarterly milestones

- Q1: Re-derive + implement a core model (e.g., MLP → attention)
- Q2: Implement a paper-level idea (even toy-scale)
- Q3: System or demo that others can run
- Q4: Consolidation + write-up (“what I actually understand now”)
